name: CI

on:
  push:
    branches:
      - main
      - master
  pull_request:
    branches:
      - main
      - master
    types:
      - opened
      - reopened
      - synchronize
      - ready_for_review

permissions:
  contents: read
  pages: write
  id-token: write

defaults:
  run:
    shell: bash

env:
  CI_IMAGE: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest

jobs:
  ruff:
    name: Ruff
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run Ruff
        run: ruff check .

  pylint:
    name: Pylint
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run Pylint
        run: pylint --errors-only .

  mypy:
    name: Mypy
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run mypy
        run: mypy

  test-index:
    name: Test Index Validation
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Generate test index
        run: python generate_test_index.py

      - name: Check if test index is up to date
        run: bash scripts/check-test-index.sh

  unit-tests:
    name: Unit Tests and Coverage
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest
    env:
      DATABASE_URL: sqlite:////tmp/secureapp-ci.db
      SESSION_SECRET: test-secret-key
      TESTING: "True"
      HYPOTHESIS_PROFILE: ci

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run tests with coverage
        id: run_tests
        run: |
          ./test-unit --coverage --summary-file coverage-report.txt
        continue-on-error: true

      - name: Publish coverage summary
        id: coverage
        if: always()
        run: |
          scripts/publish-coverage-summary.sh \
            coverage-report.txt \
            "${GITHUB_STEP_SUMMARY:-}" \
            "${GITHUB_OUTPUT:-}"

      - name: Upload coverage XML
        if: always() && steps.coverage.outputs.generated == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-xml
          path: coverage.xml

      - name: Upload HTML coverage report
        if: always() && steps.coverage.outputs.generated == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: unit-tests-html
          path: htmlcov

      - name: Fail if tests failed
        if: steps.run_tests.outcome == 'failure'
        run: exit 1

  property-tests:
    name: Property Tests
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest
    env:
      HYPOTHESIS_PROFILE: ci

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: python -m pip install -r requirements.txt

      - name: Run property tests
        id: run_property_tests
        run: |
          set -o pipefail
          pytest tests/property \
            --junitxml=property-tests-report.xml \
            | tee property-tests.log
        continue-on-error: true

      - name: Upload property test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: property-tests-results
          path: |
            property-tests-report.xml
            property-tests.log
          if-no-files-found: warn

      - name: Fail if property tests failed
        if: steps.run_property_tests.outcome == 'failure'
        run: exit 1

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest
    env:
      DATABASE_URL: sqlite:////tmp/secureapp-ci.db
      SESSION_SECRET: test-secret-key
      TESTING: "True"
      INTEGRATION_LOG_PATH: integration-tests.log

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run integration tests
        id: run_integration
        run: |
          scripts/run-integration.sh -- --junitxml=integration-tests-report.xml
        continue-on-error: true

      - name: Publish integration summary
        if: always()
        run: |
          python scripts/publish_integration_summary.py \
            --log "$INTEGRATION_LOG_PATH" \
            --junit integration-tests-report.xml

      - name: Upload integration test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-tests-results
          path: |
            integration-tests-report.xml
            ${{ env.INTEGRATION_LOG_PATH }}

      - name: Fail if integration tests failed
        if: steps.run_integration.outcome == 'failure'
        run: exit 1

  gauge-specs:
    name: Gauge Specs
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest
    env:
      DATABASE_URL: sqlite:////tmp/secureapp-ci.db
      SESSION_SECRET: test-secret-key
      TESTING: "True"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download Chromium for pyppeteer
        # GitHub Actions runs the container with HOME=/github/home, so the
        # per-job workspace still needs its own Chromium download even though
        # the base image already warmed /root/.local/share/pyppeteer.
        run: pyppeteer-install

      - name: Verify Chromium installation
        run: |
          echo "=== Checking pyppeteer installation ==="
          python3 -c "import pyppeteer; print(f'pyppeteer version: {pyppeteer.__version__}')"

          echo "=== Checking Chromium browser path ==="
          python3 -c "
          import asyncio
          from pyppeteer import launch
          from pyppeteer.chromium_downloader import current_platform, chromium_executable
          print(f'Platform: {current_platform()}')
          print(f'Expected Chromium path: {chromium_executable()}')
          import os
          if os.path.exists(chromium_executable()):
              print('✓ Chromium binary exists')
              print(f'Permissions: {oct(os.stat(chromium_executable()).st_mode)[-3:]}')
              print(f'Size: {os.stat(chromium_executable()).st_size} bytes')
          else:
              print('✗ Chromium binary NOT FOUND')
          "

          echo "=== Listing pyppeteer directory ==="
          ls -la ~/.local/share/pyppeteer/ || echo "pyppeteer directory not found"
          ls -la ~/.local/share/pyppeteer/local-chromium/ || echo "chromium directory not found"

          echo "=== Environment info ==="
          echo "HOME: $HOME"
          echo "USER: $USER"
          echo "PWD: $PWD"

      - name: Check shared library dependencies
        run: |
          echo "=== Finding Chromium binary ==="
          CHROMIUM_PATH=$(python3 -c "from pyppeteer.chromium_downloader import chromium_executable; print(chromium_executable())")
          echo "Chromium path: $CHROMIUM_PATH"

          if [ -f "$CHROMIUM_PATH" ]; then
              echo ""
              echo "=== Checking for missing shared libraries ==="
              ldd "$CHROMIUM_PATH" | grep "not found" || echo "✓ All shared libraries found"

              echo ""
              echo "=== Listing all shared library dependencies (first 30 lines) ==="
              ldd "$CHROMIUM_PATH" | head -30
          else
              echo "✗ Chromium binary not found at expected path"
              exit 1
          fi

      - name: Check system resources
        run: |
          echo "=== /dev/shm status ==="
          df -h /dev/shm || echo "/dev/shm not available"
          ls -ld /dev/shm || echo "/dev/shm directory check failed"

          echo ""
          echo "=== Memory info ==="
          free -h

          echo ""
          echo "=== Disk space ==="
          df -h /tmp

      - name: Test Chromium binary directly
        run: |
          echo "=== Running Chromium directly to capture crash output ==="
          CHROMIUM_PATH=$(python3 -c "from pyppeteer.chromium_downloader import chromium_executable; print(chromium_executable())")

          echo "Attempting to run: $CHROMIUM_PATH --version"
          timeout 5s "$CHROMIUM_PATH" --version 2>&1 || echo "Exit code: $?"

          echo ""
          echo "=== Attempting to run Chromium with browser flags ==="
          timeout 5s "$CHROMIUM_PATH" \
            --headless \
            --no-sandbox \
            --disable-dev-shm-usage \
            --disable-gpu \
            --dump-dom \
            data:text/html,test 2>&1 || echo "Exit code: $?"

      - name: Test browser launch with pyppeteer
        run: |
          python3 <<'EOF'
          import asyncio
          from pyppeteer import launch

          async def test():
              try:
                  print("Attempting to launch browser...")
                  browser = await launch(
                      headless=True,
                      handleSIGINT=False,
                      handleSIGTERM=False,
                      handleSIGHUP=False,
                      args=['--no-sandbox', '--disable-dev-shm-usage', '--disable-gpu'],
                      dumpio=True,  # Enable dumping browser process stdout/stderr
                  )
                  print("✓ Browser launched successfully")
                  page = await browser.newPage()
                  await page.setContent("<html><body><h1>Test Screenshot</h1></body></html>")
                  await page.screenshot(path='/tmp/test-screenshot.png')
                  print("✓ Screenshot captured successfully")
                  await browser.close()
                  print("✓ Browser closed cleanly")
              except Exception as e:
                  print(f"✗ Browser launch failed: {e}")
                  import traceback
                  traceback.print_exc()
                  raise

          asyncio.run(test())
          EOF

          if [ -f /tmp/test-screenshot.png ]; then
              echo "Screenshot file created successfully"
              echo "File size: $(stat -c%s /tmp/test-screenshot.png) bytes"
          else
              echo "✗ Screenshot file was not created"
              exit 1
          fi

      - name: Run Gauge specs
        id: run_gauge
        run: ./test-gauge
        env:
          GAUGE_PYTHON_COMMAND: python3
          STEP_IMPL_DIR: "${{ github.workspace }}/step_impl"
          PYTHONPATH: "${{ github.workspace }}:${{ github.workspace }}/step_impl:${{ github.workspace }}/tests"
          PYPPETEER_DEBUG: "1"
          DEBUG: "pyppeteer:*"
        continue-on-error: true

      - name: Upload Gauge HTML report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: gauge-html
          path: reports/html-report
          if-no-files-found: warn

      - name: Fail if Gauge specs failed
        if: steps.run_gauge.outcome == 'failure'
        run: exit 1

  deploy-reports:
    name: Publish Test Reports
    needs:
      - unit-tests
      - integration-tests
      - gauge-specs
      - property-tests
    if: ${{ always() && github.event_name == 'push' && github.ref == 'refs/heads/main' }}
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/${{ github.repository_owner }}/viewer-ci:latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download unit test report
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: unit-tests-html
          path: site/unit-tests

      - name: Download Gauge report
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: gauge-html
          path: site/gauge-specs

      - name: Download integration test results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: integration-tests-results
          path: site/integration-tests

      - name: Download property test results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: property-tests-results
          path: site/property-tests

      - name: Prepare site content
        run: |
          python scripts/build-report-site.py \
            --unit-tests-artifacts site/unit-tests \
            --gauge-artifacts site/gauge-specs \
            --integration-artifacts site/integration-tests \
            --property-artifacts site/property-tests \
            --output site

      - name: Upload artifact for GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
